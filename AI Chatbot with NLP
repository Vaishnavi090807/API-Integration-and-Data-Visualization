import nltk
nltk.download('punkt') 
from nltk.tokenize import word_tokenize
from nltk.corpus import wordnet
from nltk.stem import WordNetLemmatizer
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
import random
import string

nltk.download('punkt')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')

lemmatizer = WordNetLemmatizer()

intents = {
    "greeting": {
        "patterns": ["hello", "hi", "hey", "good morning", "good evening"],
        "responses": ["Hello! How can I assist you today?", "Hi there!", "Hey! What's up?"]
    },
    "farewell": {
        "patterns": ["bye", "goodbye", "see you", "take care"],
        "responses": ["Goodbye! Have a great day!", "See you later!", "Take care!"]
    },
    "help": {
        "patterns": ["help", "what can you do", "assist", "support"],
        "responses": ["I can answer basic questions, greet you, or say goodbye. Try asking something like 'What's your name?' or 'Tell me about AI.'"]
    },
    "name": {
        "patterns": ["what is your name", "who are you", "your name"],
        "responses": ["I'm Grok, a simple chatbot created for CodTech!", "My name is Grok, nice to meet you!"]
    },
    "ai_info": {
        "patterns": ["tell me about ai", "what is ai", "artificial intelligence"],
        "responses": ["AI, or Artificial Intelligence, is the simulation of human intelligence in machines. It includes tasks like learning, reasoning, and problem-solving. Want to know more?"]
    }
}

def get_wordnet_pos(word):
    tag = nltk.pos_tag([word])[0][1][0].upper()
    tag_dict = {"J": wordnet.ADJ, "N": wordnet.NOUN, "V": wordnet.VERB, "R": wordnet.ADV}
    return tag_dict.get(tag, wordnet.NOUN)

def preprocess_text(text):
    tokens = word_tokenize(text.lower())
    tokens = [token for token in tokens if token not in string.punctuation]
    tokens = [lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in tokens]
    return " ".join(tokens)
def get_cosine_similarity(text1, text2):
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform([text1, text2])
    return (tfidf_matrix * tfidf_matrix.T).A[0, 1]

def get_intent(user_input):
    processed_input = preprocess_text(user_input)
    max_similarity = 0
    best_intent = None

    for intent, data in intents.items():
        for pattern in data["patterns"]:
            processed_pattern = preprocess_text(pattern)
            similarity = get_cosine_similarity(processed_input, processed_pattern)
            if similarity > max_similarity and similarity > 0.3: 
                max_similarity = similarity
                best_intent = intent

    return best_intent
def get_response(intent):
    if intent and intent in intents:
        return random.choice(intents[intent]["responses"])
    return "Sorry, I didn't understand that. Try saying 'help' for more info."
def chatbot():
    print("Welcome to the CodTech Chatbot! Type 'exit' to quit.")
    while True:
        user_input = input("You: ")
        if user_input.lower() == "exit":
            print("Bot: Goodbye!")
            break
        intent = get_intent(user_input)
        response = get_response(intent)
        print(f"Bot: {response}")

if __name__ == "__main__":
    chatbot()
